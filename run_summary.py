import pathlib
import pandas as pd
import argparse # å¯¼å…¥ argparse åº“

# --- 1. é…ç½® (å¸¸é‡éƒ¨åˆ†) ---

# å®šä¹‰å¸¸é‡ä»¥é¿å…æ‹¼å†™é”™è¯¯
DATASET_COL = 'dataset'
METRIC_COL = 'metric'

# --- 2. è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜) ---

def get_value_from_df(df, value_col, dataset_filter_value, metric_filter_value=None, 
                      dataset_is_prefix=False, average=False, default_value="N/A"):
    """
    æ ¹æ®æ¡ä»¶ä» DataFrame ä¸­æå–å•ä¸ªå€¼æˆ–å¹³å‡å€¼ã€‚
    """
    if value_col not in df.columns:
        return f"åˆ—ç¼ºå¤±"

    filtered_df = df.copy()

    if dataset_is_prefix:
        if pd.isna(dataset_filter_value) or dataset_filter_value == "":
             return default_value
        filtered_df = filtered_df[filtered_df[DATASET_COL].astype(str).str.startswith(str(dataset_filter_value), na=False)]
    else:
        filtered_df = filtered_df[filtered_df[DATASET_COL] == dataset_filter_value]

    if metric_filter_value:
        filtered_df = filtered_df[filtered_df[METRIC_COL] == metric_filter_value]

    if filtered_df.empty:
        return default_value

    values = pd.to_numeric(filtered_df[value_col], errors='coerce')

    if average:
        if values.isna().all():
            return "error" 
        mean_val = values.mean()
        return mean_val if not pd.isna(mean_val) else "error"
    else:
        valid_values = values.dropna()
        if valid_values.empty:
            original_values = filtered_df[value_col].dropna()
            if not original_values.empty:
                return "error"
            return default_value
        
        return valid_values.iloc[0]

# --- 3. ä¸»é€»è¾‘å‡½æ•° (ç°åœ¨æ¥æ”¶å‚æ•°) ---

def process_and_summarize(source_dir: pathlib.Path, dest_dir: pathlib.Path, model_column: str):
    """
    ä¸»å‡½æ•°ï¼Œæ‰§è¡ŒæŸ¥æ‰¾ã€è§£æã€æå–å’Œæ±‡æ€»æ“ä½œã€‚

    Args:
        source_dir (pathlib.Path): åŒ…å«åŸå§‹ç»“æœçš„æºç›®å½•ã€‚
        dest_dir (pathlib.Path): ç”¨äºå­˜æ”¾æœ€ç»ˆ summary.csv æ–‡ä»¶çš„ç›®æ ‡ç›®å½•ã€‚
        model_column (str): CSV æ–‡ä»¶ä¸­åŒ…å«æ¨¡å‹åˆ†æ•°çš„åˆ—åã€‚
    """
    # æ­¥éª¤ A: æ£€æŸ¥å’Œè®¾ç½®ç›®å½•
    if not source_dir.is_dir():
        print(f"âŒ é”™è¯¯ï¼šæºç›®å½• '{source_dir}' ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
        return

    dest_dir.mkdir(exist_ok=True)
    print(f"æºç›®å½•: {source_dir}")
    print(f"ç›®æ ‡ç›®å½•: {dest_dir}")
    print(f"ç›®æ ‡æ¨¡å‹åˆ—: {model_column}")
    print("---")

    # æ­¥éª¤ B: é€’å½’æŸ¥æ‰¾æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„ csv æ–‡ä»¶
    csv_files_found = list(source_dir.glob("**/summary/summary_*.csv"))

    if not csv_files_found:
        print("ğŸŸ¡ æœªåœ¨æºç›®å½•ä¸­æ‰¾åˆ°ä»»ä½• 'summary/summary_*.csv' æ–‡ä»¶ã€‚")
        return

    # æ­¥éª¤ C: å®šä¹‰æ•°æ®æå–è§„åˆ™
    processing_rules = [
        ('drop', 'drop', 'accuracy', False, False),
        ('IFEval', 'IFEval', None, False, True),
        ('agieval', 'agieval', 'naive_average', False, False),
        ('mmlu_pro', 'mmlu_pro','accuracy', True, True),
        ('gsm8k', 'gsm8k', 'accuracy', False, False),
        ('math', 'math', 'accuracy', False, False),
        ('math_prm800k_500', 'math_prm800k_500', 'accuracy', False, False),
        ('OmniMath', 'OmniMath', None, False, False),
        ('OlympiadBench_OE_TO_maths_en_COMP', 'OlympiadBench_OE_TO_maths_en_COMP', 'accuracy', False, False)
        ('aime2024_accuracy', 'aime2024', 'accuracy', True, True),
        ('openai_humaneval', 'openai_humaneval', None, False, False),
        ('sanitized_mbpp_score', 'sanitized_mbpp', 'score', False, False),
        ('lcb_code_generation', 'lcb_code_generation', None, False, False),
        ('humaneval_plus', 'humaneval_plus', None, False, False),
        ('ARC-c', 'ARC-c', 'accuracy', False, False),
        ('bbh_naive_average', 'bbh', 'naive_average', False, False),
        ('GPQA_diamond', 'GPQA_diamond', 'accuracy', False, False),
        ('calm_Accuracy', 'calm', 'Accuracy', True, True),
        ('korbench', 'korbench', 'accuracy', True, True),
    ]
    
    all_results = []
    processed_count = 0

    # æ­¥éª¤ D: éå†æ–‡ä»¶ï¼Œç”Ÿæˆæ–°æ–‡ä»¶åå¹¶æå–æ•°æ®
    for csv_path in csv_files_found:
        print(f"ğŸ” æ­£åœ¨å¤„ç†æ–‡ä»¶: {csv_path}")
        
        try:
            summary_dir = csv_path.parent
            ts_dir = summary_dir.parent
            top_dir = ts_dir.parent
            top_dir_name = top_dir.name
            ts_dir_name = ts_dir.name
            
            parts = top_dir_name.rsplit('_', 1)
            main_part, suffix = parts[0], parts[1]
            prefix = main_part.rsplit('_', 1)[0]
            
            new_filename = f"{prefix}-{ts_dir_name}-{suffix}.csv"
            
        except IndexError:
            print(f"  âš ï¸ è·³è¿‡æ–‡ä»¶ï¼Œå…¶çˆ¶ç›®å½•å‘½åæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ: {top_dir.name}")
            print("---")
            continue
        
        try:
            df = pd.read_csv(csv_path)
            
            if model_column not in df.columns:
                print(f"  âš ï¸ è·³è¿‡æ–‡ä»¶ï¼Œå› ç¼ºå°‘ç›®æ ‡åˆ— '{model_column}'ã€‚")
                print("---")
                continue
            
            if DATASET_COL not in df.columns or METRIC_COL not in df.columns:
                print(f"  âš ï¸ è·³è¿‡æ–‡ä»¶ï¼Œå› ç¼ºå°‘ '{DATASET_COL}' æˆ– '{METRIC_COL}' åˆ—ã€‚")
                print("---")
                continue

            file_summary = {'filename': new_filename}

            for stat_key, dataset_val, metric_val, is_prefix, needs_avg in processing_rules:
                value = get_value_from_df(
                    df,
                    value_col=model_column, # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°
                    dataset_filter_value=dataset_val,
                    metric_filter_value=metric_val,
                    dataset_is_prefix=is_prefix,
                    average=needs_avg,
                    default_value="N/A"
                )
                file_summary[stat_key] = value
            
            all_results.append(file_summary)
            processed_count += 1
            print(f"  -> æˆåŠŸæå–æ•°æ®ï¼Œæ ‡è¯†ä¸º: {new_filename}")
            print("---")

        except pd.errors.EmptyDataError:
            print(f"  âš ï¸ è·³è¿‡æ–‡ä»¶ï¼Œå› ä¸ºæ–‡ä»¶ä¸ºç©º: {csv_path}")
            print("---")
            continue
        except Exception as e:
            print(f"  âŒ å¤„ç†æ–‡ä»¶ {csv_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            print("---")
            continue

    # æ­¥éª¤ E: åˆ›å»ºå¹¶ä¿å­˜æœ€ç»ˆçš„ summary æ–‡ä»¶
    if not all_results:
        print("ğŸŸ¡ æœªèƒ½ä»ä»»ä½•æ–‡ä»¶ä¸­æˆåŠŸæå–æ•°æ®ã€‚")
        return

    summary_df = pd.DataFrame(all_results)
    
    if 'filename' in summary_df.columns:
        summary_df.set_index('filename', inplace=True)
    
    output_columns = [rule[0] for rule in processing_rules]
    summary_df = summary_df.reindex(columns=output_columns) 

    # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°æ¥æ„å»ºè¾“å‡ºæ–‡ä»¶å
    output_file_path = dest_dir / f"summary_{model_column}.csv"
    try:
        summary_df.to_csv(output_file_path)
        print(f"\nğŸ‰ è„šæœ¬æ‰§è¡Œå®Œæ¯•ï¼å…±å¤„ç†äº† {processed_count} ä¸ªæ–‡ä»¶ã€‚")
        print(f"æœ€ç»ˆæ±‡æ€»æ–‡ä»¶å·²ä¿å­˜è‡³: {output_file_path}")
    except Exception as e:
        print(f"\nâŒ å†™å…¥æœ€ç»ˆæ±‡æ€»æ–‡ä»¶æ—¶å‡ºé”™: {e}")


# --- 4. å‘½ä»¤è¡Œå‚æ•°è§£æå’Œä¸»ç¨‹åºå…¥å£ ---
def main():
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°å¹¶å¯åŠ¨ä¸»å¤„ç†å‡½æ•°ã€‚
    """
    parser = argparse.ArgumentParser(
        description="æŸ¥æ‰¾ã€å¤„ç†å¹¶æ±‡æ€»æ¨¡å‹è¯„ä¼°çš„ CSV ç»“æœæ–‡ä»¶ã€‚",
        formatter_class=argparse.RawTextHelpFormatter # ä¿æŒå¸®åŠ©æ–‡æœ¬æ ¼å¼
    )
    
    parser.add_argument(
        "-s", "--source-dir",
        type=str,
        required=True,
        help="å¿…é¡»ï¼šåŒ…å«åŸå§‹ç»“æœçš„æºç›®å½•è·¯å¾„ã€‚\nä¾‹å¦‚: outputs"
    )
    
    parser.add_argument(
        "-d", "--dest-dir",
        type=str,
        required=True,
        help="å¿…é¡»ï¼šç”¨äºå­˜æ”¾æœ€ç»ˆ summary.csv æ–‡ä»¶çš„ç›®æ ‡ç›®å½•è·¯å¾„ã€‚\nä¾‹å¦‚: res"
    )
    
    parser.add_argument(
        "-m", "--model-column",
        type=str,
        required=True,
        help="å¿…é¡»ï¼šåœ¨ CSV æ–‡ä»¶ä¸­åŒ…å«æ¨¡å‹åˆ†æ•°çš„åˆ—åã€‚\nä¾‹å¦‚: qwen2.5-7b-instruct-vllm"
    )
    
    args = parser.parse_args()
    
    # å°†å­—ç¬¦ä¸²è·¯å¾„è½¬æ¢ä¸º pathlib.Path å¯¹è±¡
    source_path = pathlib.Path(args.source_dir)
    dest_path = pathlib.Path(args.dest_dir)
    
    # ä½¿ç”¨è§£æåˆ°çš„å‚æ•°è°ƒç”¨ä¸»å‡½æ•°
    process_and_summarize(source_path, dest_path, args.model_column)


if __name__ == "__main__":
    main()

